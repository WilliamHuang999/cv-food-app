{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nfrom keras.utils import img_to_array, load_img\nimport numpy as np\nimport cv2 as cv\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\n\ntrainPath = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training'\ntestPath = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test'\n\nbatchSize = 64      # Reduce value if you have less GPU\n\n# # Read in example image and get shape\n# img = load_img(trainPath + \"/Quince/0_100.jpg\")\n# plt.imshow(img)\n# plt.show()\n\n# imgA = img_to_array(img)\n# print(imgA.shape)        \n# Build model\nmodel = Sequential()\nmodel.add(Conv2D(filters=128, kernel_size=3, activation=\"relu\", input_shape=(100,100,3)))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(filters=64, kernel_size=3, activation=\"relu\"))\nmodel.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(5000, activation=\"relu\"))\nmodel.add(Dense(1000, activation=\"relu\"))\nmodel.add(Dense(131, activation=\"softmax\"))\n\nprint(model.summary())\n\n\n# Compile model\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\n# Load data\ntrain_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.3, horizontal_flip=True, vertical_flip=True, zoom_range=0.3)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(trainPath, target_size=(100,100), batch_size=batchSize, color_mode=\"rgb\", class_mode=\"categorical\", shuffle=True)\n\n\ntest_generator = test_datagen.flow_from_directory(testPath, target_size=(100,100), batch_size=batchSize, color_mode=\"rgb\", class_mode=\"categorical\")\n\nstepsPerEpoch = np.ceil(train_generator.samples / batchSize)\nvalidationSteps = np.ceil(test_generator.samples / batchSize)\n\n# Early stopping\nstop_early = EarlyStopping(monitor=\"val_accuracy\", patience=5)      # Stop fitting model if it doesn't improve by 5\n\nhistory = model.fit(train_generator, steps_per_epoch=stepsPerEpoch, epochs=5, validation_data=test_generator, validation_steps=validationSteps, callbacks=[stop_early])\n\nmodel.save(\"/kaggle/working/fruits360.h5\")     # Add file path to save the model to","metadata":{"_uuid":"8bc14dc0-1c02-4a72-96c2-bf27321b7876","_cell_guid":"6a03741b-6dd5-435e-8d8d-ffb6989d96da","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-02T22:37:24.268025Z","iopub.execute_input":"2023-07-02T22:37:24.268416Z","iopub.status.idle":"2023-07-02T23:02:47.068551Z","shell.execute_reply.started":"2023-07-02T22:37:24.268381Z","shell.execute_reply":"2023-07-02T23:02:47.067527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing model","metadata":{}},{"cell_type":"code","source":"!pip uninstall opencv-python-headless -y \n!pip install opencv-python --upgrade\nimport tensorflow as tf\nimport os\nfrom keras.utils import img_to_array, load_img\nimport numpy as np\nimport cv2 as cv\n\n# Load model\nmodel = tf.keras.models.load_model(\"/kaggle/working/fruits360.h5\")       # Put in model path here\nprint(model.summary())\n\n# Load categories\nsource_folder = \"/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test\"\ncategories = os.listdir(source_folder)\n# categories = categories.sort()\nprint(categories)\nprint(len(categories))      # Should be 131\n\n# Load and prepare image\ndef prepareImage(path):\n    img = load_img(path, target_size=(100,100))\n    imgArray = img_to_array(img)\n    # print(imgArray.shape)\n    imgArray = np.expand_dims(imgArray, axis=0)\n    imgArray = imgArray / 255.\n    return imgArray\n\ntestImgPath = \"/kaggle/input/eggplant/eggplant.jpg\"\nimageForModel = prepareImage(testImgPath)\n\nresultArray = model.predict(imageForModel, verbose=1)\nanswers = np.argmax(resultArray, axis=1)\nprint(categories[answers[0]])\n\n# Show image with text below\nimg = cv.imread(testImgPath)\ncv.putText(img, categories[answers[0]],(0,50), cv.FONT_HERSHEY_COMPLEX, 1, (209, 19, 77), 2)\ncv.imshow('img', img)\ncv.waitKey(0)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-13T21:09:07.305597Z","iopub.status.idle":"2023-07-13T21:09:07.305993Z","shell.execute_reply.started":"2023-07-13T21:09:07.305785Z","shell.execute_reply":"2023-07-13T21:09:07.305803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow-gpu==2.10\nfrom tpot import TPOTClassifier\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\n\ndigits = load_digits()\nX_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target,\n                                                    train_size=0.75, test_size=0.25)\n\ntpot = TPOTClassifier(generations=5, population_size=50, verbosity=2)\ntpot.fit(X_train, y_train)\nprint(tpot.score(X_test, y_test))\ntpot.export('tpot_digits_pipeline.py')","metadata":{"execution":{"iopub.status.busy":"2023-07-14T20:25:29.944169Z","iopub.execute_input":"2023-07-14T20:25:29.944556Z","iopub.status.idle":"2023-07-14T21:05:35.648412Z","shell.execute_reply.started":"2023-07-14T20:25:29.944522Z","shell.execute_reply":"2023-07-14T21:05:35.645350Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Invalid requirement: '=='\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"690dad9a04ea4b2fbdfeee8fcda706af"}},"metadata":{}},{"name":"stdout","text":"\nGeneration 1 - Current best internal CV score: 0.9777282114828584\n\nGeneration 2 - Current best internal CV score: 0.9777282114828584\n\nGeneration 3 - Current best internal CV score: 0.9777282114828584\n\nGeneration 4 - Current best internal CV score: 0.9799586947542338\n\nGeneration 5 - Current best internal CV score: 0.9807049428610768\n\nBest pipeline: MLPClassifier(MaxAbsScaler(input_matrix), alpha=0.01, learning_rate_init=0.01)\n0.9755555555555555\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Hyperparameter Tuning 2","metadata":{}},{"cell_type":"code","source":"import keras_tuner as kt\nimport tensorflow as tf\nimport os\nfrom keras.utils import img_to_array, load_img\nimport numpy as np\nimport cv2 as cv\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\n\n#class MyHyperModel(kt.HyperModel):\ndef build(hp):\n    model = Sequential()\n    model.add(Conv2D(filters=128, kernel_size=3, activation=hp.Choice('activation', ['relu', 'PReLU', 'elu']), input_shape=(100,100,3)))\n    model.add(MaxPooling2D())\n    model.add(Conv2D(filters=64, kernel_size=3, activation=\"relu\"))\n    model.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\n    model.add(MaxPooling2D())\n    model.add(Dropout(rate=hp.Float('rate',min_value=0.3,max_value=0.8,step=0.1)))\n    model.add(Flatten())\n    model.add(Dense(units=hp.Int('units',3000,8000,500), activation=hp.Choice('activation_2', ['relu', 'PReLU', 'elu'])))\n    model.add(Dense(units=hp.Int('units_2',500,1500,250), activation=\"relu\"))\n    model.add(Dense(131, activation=\"softmax\"))\n    #model.add(keras.layers.Dense(\n     #   hp.Choice('units', [8, 16, 32]),\n      #  activation='relu'))\n   # model.add(keras.layers.Dense(1, activation='relu'))\n    model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n    \n    print(model.summary())\n    return model\n\n#def fit(hp, model):\n    # Early stopping\n#stop_early = EarlyStopping(monitor=\"val_accuracy\", patience=5)      # Stop fitting model if it doesn't improve by 5\n\n#history = model.fit(train_generator, steps_per_epoch=stepsPerEpoch, epochs=5, validation_data=test_generator, validation_steps=validationSteps, callbacks=[stop_early])\n\n\ntrainPath = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training'\ntestPath = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test'\n\nbatchSize = 64      # Reduce value if you have less GPU\n\n# Load data\ntrain_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.3, horizontal_flip=True, vertical_flip=True, zoom_range=0.3)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(trainPath, target_size=(100,100), batch_size=batchSize, color_mode=\"rgb\", class_mode=\"categorical\", shuffle=True)\n\n\ntest_generator = test_datagen.flow_from_directory(testPath, target_size=(100,100), batch_size=batchSize, color_mode=\"rgb\", class_mode=\"categorical\")\n#x = MyHyperMode(kt.HyperModel)\n#build(kt.HyperParameters())\n#tuner = kt.Hyperband(hypermodel = build, objective=\"val_accuracy\", max_epochs=10, hyperband_iterations=10,seed=1,max_retries_per_trial=0, max_consecutive_failed_trials=3)\ntuner = kt.RandomSearch(hypermodel = build, objective=\"val_accuracy\", max_trials=10,executions_per_trial=1,overwrite=False)\n#tuner.search_space_summary()\ntuner.search(train_generator,epochs=2,validation_data=test_generator)\ntuner.results_summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T17:57:55.346565Z","iopub.execute_input":"2023-07-16T17:57:55.346981Z","iopub.status.idle":"2023-07-16T19:25:22.615484Z","shell.execute_reply.started":"2023-07-16T17:57:55.346944Z","shell.execute_reply":"2023-07-16T19:25:22.613901Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Trial 10 Complete [00h 11m 44s]\nval_accuracy: 0.9436706900596619\n\nBest val_accuracy So Far: 0.9436706900596619\nTotal elapsed time: 01h 27m 25s\nResults summary\nResults in ./untitled_project\nShowing 10 best trials\nObjective(name=\"val_accuracy\", direction=\"max\")\n\nTrial 09 summary\nHyperparameters:\nactivation: relu\nrate: 0.4\nunits: 4000\nactivation_2: relu\nunits_2: 1500\nlearning_rate: 0.1\nScore: 0.9436706900596619\n\nTrial 07 summary\nHyperparameters:\nactivation: PReLU\nrate: 0.3\nunits: 3500\nactivation_2: PReLU\nunits_2: 1250\nlearning_rate: 0.01\nScore: 0.9378526210784912\n\nTrial 05 summary\nHyperparameters:\nactivation: relu\nrate: 0.4\nunits: 6000\nactivation_2: relu\nunits_2: 1500\nlearning_rate: 0.1\nScore: 0.9287288188934326\n\nTrial 03 summary\nHyperparameters:\nactivation: elu\nrate: 0.4\nunits: 8000\nactivation_2: relu\nunits_2: 1250\nlearning_rate: 0.001\nScore: 0.9250705242156982\n\nTrial 08 summary\nHyperparameters:\nactivation: PReLU\nrate: 0.6000000000000001\nunits: 5000\nactivation_2: relu\nunits_2: 500\nlearning_rate: 0.001\nScore: 0.9245857000350952\n\nTrial 04 summary\nHyperparameters:\nactivation: PReLU\nrate: 0.4\nunits: 4500\nactivation_2: PReLU\nunits_2: 1000\nlearning_rate: 0.001\nScore: 0.923351526260376\n\nTrial 06 summary\nHyperparameters:\nactivation: relu\nrate: 0.4\nunits: 8000\nactivation_2: PReLU\nunits_2: 1000\nlearning_rate: 0.001\nScore: 0.9208391904830933\n\nTrial 00 summary\nHyperparameters:\nactivation: relu\nrate: 0.7\nunits: 3000\nactivation_2: relu\nunits_2: 1000\nlearning_rate: 1.0\nScore: 0.014456981793045998\n\nTrial 01 summary\nHyperparameters:\nactivation: relu\nrate: 0.3\nunits: 3000\nactivation_2: PReLU\nunits_2: 1250\nlearning_rate: 1.0\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 213, in _build_and_fit_model\n    model = self._try_build(hp)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 155, in _try_build\n    model = self._build_hypermodel(hp)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 146, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n  File \"/tmp/ipykernel_28/3913047079.py\", line 30, in build\n    model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam, metrics=[\"accuracy\"])\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/conda/lib/python3.10/site-packages/keras/optimizers/__init__.py\", line 318, in get\n    raise ValueError(\nValueError: Could not interpret optimizer identifier: <class 'keras.optimizers.adam.Adam'>\n\n\nTrial 02 summary\nHyperparameters:\nactivation: elu\nrate: 0.3\nunits: 4000\nactivation_2: relu\nunits_2: 1500\nlearning_rate: 0.01\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 213, in _build_and_fit_model\n    model = self._try_build(hp)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 155, in _try_build\n    model = self._build_hypermodel(hp)\n  File \"/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 146, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n  File \"/tmp/ipykernel_28/3913047079.py\", line 30, in build\n    model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam, metrics=[\"accuracy\"])\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/conda/lib/python3.10/site-packages/keras/optimizers/__init__.py\", line 318, in get\n    raise ValueError(\nValueError: Could not interpret optimizer identifier: <class 'keras.optimizers.adam.Adam'>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}