{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "# import os\n",
    "# from keras.utils import img_to_array, load_img\n",
    "# import numpy as np\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# import pandas as pd\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "trainPath = r\"C:\\Users\\gener\\OneDrive\\Documents\\fruits360\\fruits-360\\train-small\"\n",
    "testPath = r\"C:\\Users\\gener\\OneDrive\\Documents\\fruits360\\fruits-360\\test-small\"\n",
    "\n",
    "batchSize = 64      # Reduce value if you have less GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WATCH VIDEO FOR IMAGE PRE-PROCESSING\n",
    "# LOOK AT KAGGLE TO SEE HOW IMAGE PRE-PROCESSING IS DONE\n",
    "# CHAT-GPT\n",
    "\n",
    "model = Sequential()\n",
    "mobileNet = MobileNetV2(input_shape=(100,100,3), include_top=False, classes=5)\n",
    "for layer in mobileNet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.add(mobileNet)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Load data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.3, horizontal_flip=True, vertical_flip=True, zoom_range=0.3)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(trainPath, target_size=(100,100), batch_size=batchSize, color_mode=\"rgb\", class_mode=\"categorical\", shuffle=True)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(trainPath, target_size=(100,100), batch_size=batchSize, color_mode=\"rgb\", class_mode=\"categorical\")\n",
    "\n",
    "stepsPerEpoch = np.ceil(train_generator.samples / batchSize)\n",
    "validationSteps = np.ceil(test_generator.samples / batchSize)\n",
    "\n",
    "# Early stopping\n",
    "stop_early = EarlyStopping(monitor=\"val_accuracy\", patience=5, min_delta=0.001, restore_best_weights=True)\n",
    "\n",
    "history = modelv2.fit(train_generator, steps_per_epoch=stepsPerEpoch, epochs=50, validation_data=test_generator, validation_steps=validationSteps, callbacks=[stop_early])\n",
    "\n",
    "modelv2.save(r\"C:\\Users\\gener\\OneDrive\\Documents\\cv-food-app\\fruits360Model-v2.h5\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
