{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nfrom keras.utils import img_to_array, load_img\nimport numpy as np\nimport cv2 as cv\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\n\ntrainPath = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training'\ntestPath = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test'\n\nbatchSize = 64      # Reduce value if you have less GPU\n\n# # Read in example image and get shape\n# img = load_img(trainPath + \"/Quince/0_100.jpg\")\n# plt.imshow(img)\n# plt.show()\n\n# imgA = img_to_array(img)\n# print(imgA.shape)\n\n# Build model\nmodel = Sequential()\nmodel.add(Conv2D(filters=128, kernel_size=3, activation=\"relu\", input_shape=(100,100,3)))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(filters=64, kernel_size=3, activation=\"relu\"))\nmodel.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(5000, activation=\"relu\"))\nmodel.add(Dense(1000, activation=\"relu\"))\nmodel.add(Dense(131, activation=\"softmax\"))\n\nprint(model.summary())\n\n# Compile model\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n\n# Load data\ntrain_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.3, horizontal_flip=True, vertical_flip=True, zoom_range=0.3)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(trainPath, target_size=(100,100), batch_size=batchSize, color_mode=\"rgb\", class_mode=\"categorical\", shuffle=True)\n\n\ntest_generator = test_datagen.flow_from_directory(testPath, target_size=(100,100), batch_size=batchSize, color_mode=\"rgb\", class_mode=\"categorical\")\n\nstepsPerEpoch = np.ceil(train_generator.samples / batchSize)\nvalidationSteps = np.ceil(test_generator.samples / batchSize)\n\n# Early stopping\nstop_early = EarlyStopping(monitor=\"val_accuracy\", patience=5)      # Stop fitting model if it doesn't improve by 5\n\nhistory = model.fit(train_generator, steps_per_epoch=stepsPerEpoch, epochs=5, validation_data=test_generator, validation_steps=validationSteps, callbacks=[stop_early])\n\nmodel.save(\"/kaggle/working/fruits360.h5\")     # Add file path to save the model to","metadata":{"_uuid":"8bc14dc0-1c02-4a72-96c2-bf27321b7876","_cell_guid":"6a03741b-6dd5-435e-8d8d-ffb6989d96da","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-02T22:37:24.268025Z","iopub.execute_input":"2023-07-02T22:37:24.268416Z","iopub.status.idle":"2023-07-02T23:02:47.068551Z","shell.execute_reply.started":"2023-07-02T22:37:24.268381Z","shell.execute_reply":"2023-07-02T23:02:47.067527Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_3 (Conv2D)           (None, 98, 98, 128)       3584      \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 49, 49, 128)      0         \n 2D)                                                             \n                                                                 \n conv2d_4 (Conv2D)           (None, 47, 47, 64)        73792     \n                                                                 \n conv2d_5 (Conv2D)           (None, 45, 45, 32)        18464     \n                                                                 \n max_pooling2d_3 (MaxPooling  (None, 22, 22, 32)       0         \n 2D)                                                             \n                                                                 \n dropout_1 (Dropout)         (None, 22, 22, 32)        0         \n                                                                 \n flatten_1 (Flatten)         (None, 15488)             0         \n                                                                 \n dense_3 (Dense)             (None, 5000)              77445000  \n                                                                 \n dense_4 (Dense)             (None, 1000)              5001000   \n                                                                 \n dense_5 (Dense)             (None, 131)               131131    \n                                                                 \n=================================================================\nTotal params: 82,672,971\nTrainable params: 82,672,971\nNon-trainable params: 0\n_________________________________________________________________\nNone\nFound 67692 images belonging to 131 classes.\nFound 22688 images belonging to 131 classes.\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"2023-07-02 22:37:28.201089: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"1058/1058 [==============================] - 276s 260ms/step - loss: 3.5241 - accuracy: 0.1491 - val_loss: 1.9349 - val_accuracy: 0.4614\nEpoch 2/5\n1058/1058 [==============================] - 276s 261ms/step - loss: 1.3912 - accuracy: 0.5662 - val_loss: 0.7682 - val_accuracy: 0.7680\nEpoch 3/5\n1058/1058 [==============================] - 274s 259ms/step - loss: 0.6346 - accuracy: 0.7964 - val_loss: 0.5061 - val_accuracy: 0.8531\nEpoch 4/5\n1058/1058 [==============================] - 277s 262ms/step - loss: 0.4012 - accuracy: 0.8809 - val_loss: 0.3317 - val_accuracy: 0.8969\nEpoch 5/5\n1058/1058 [==============================] - 276s 261ms/step - loss: 0.2214 - accuracy: 0.9300 - val_loss: 0.2843 - val_accuracy: 0.9164\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Testing model","metadata":{}},{"cell_type":"code","source":"!pip uninstall opencv-python-headless -y \n!pip install opencv-python --upgrade\nimport tensorflow as tf\nimport os\nfrom keras.utils import img_to_array, load_img\nimport numpy as np\nimport cv2 as cv\n\n# Load model\nmodel = tf.keras.models.load_model(\"/kaggle/working/fruits360.h5\")       # Put in model path here\nprint(model.summary())\n\n# Load categories\nsource_folder = \"/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test\"\ncategories = os.listdir(source_folder)\n# categories = categories.sort()\nprint(categories)\nprint(len(categories))      # Should be 131\n\n# Load and prepare image\ndef prepareImage(path):\n    img = load_img(path, target_size=(100,100))\n    imgArray = img_to_array(img)\n    # print(imgArray.shape)\n    imgArray = np.expand_dims(imgArray, axis=0)\n    imgArray = imgArray / 255.\n    return imgArray\n\ntestImgPath = \"/kaggle/input/eggplant/eggplant.jpg\"\nimageForModel = prepareImage(testImgPath)\n\nresultArray = model.predict(imageForModel, verbose=1)\nanswers = np.argmax(resultArray, axis=1)\nprint(categories[answers[0]])\n\n# Show image with text below\nimg = cv.imread(testImgPath)\ncv.putText(img, categories[answers[0]],(0,50), cv.FONT_HERSHEY_COMPLEX, 1, (209, 19, 77), 2)\ncv.imshow('img', img)\ncv.waitKey(0)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-02T23:27:00.470324Z","iopub.execute_input":"2023-07-02T23:27:00.470742Z","iopub.status.idle":"2023-07-02T23:27:17.337677Z","shell.execute_reply.started":"2023-07-02T23:27:00.470705Z","shell.execute_reply":"2023-07-02T23:27:17.336443Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Found existing installation: opencv-python-headless 4.7.0.72\nUninstalling opencv-python-headless-4.7.0.72:\n  Successfully uninstalled opencv-python-headless-4.7.0.72\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.8.0.74)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_3 (Conv2D)           (None, 98, 98, 128)       3584      \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 49, 49, 128)      0         \n 2D)                                                             \n                                                                 \n conv2d_4 (Conv2D)           (None, 47, 47, 64)        73792     \n                                                                 \n conv2d_5 (Conv2D)           (None, 45, 45, 32)        18464     \n                                                                 \n max_pooling2d_3 (MaxPooling  (None, 22, 22, 32)       0         \n 2D)                                                             \n                                                                 \n dropout_1 (Dropout)         (None, 22, 22, 32)        0         \n                                                                 \n flatten_1 (Flatten)         (None, 15488)             0         \n                                                                 \n dense_3 (Dense)             (None, 5000)              77445000  \n                                                                 \n dense_4 (Dense)             (None, 1000)              5001000   \n                                                                 \n dense_5 (Dense)             (None, 131)               131131    \n                                                                 \n=================================================================\nTotal params: 82,672,971\nTrainable params: 82,672,971\nNon-trainable params: 0\n_________________________________________________________________\nNone\n['Quince', 'Grapefruit White', 'Granadilla', 'Orange', 'Apple Red 3', 'Grape White 2', 'Corn Husk', 'Tamarillo', 'Banana Red', 'Nectarine Flat', 'Pepper Yellow', 'Nut Forest', 'Pear Monster', 'Fig', 'Tomato Heart', 'Onion Red Peeled', 'Lemon Meyer', 'Onion Red', 'Passion Fruit', 'Cucumber Ripe', 'Cactus fruit', 'Tomato not Ripened', 'Mango Red', 'Apple Pink Lady', 'Pomegranate', 'Plum', 'Pineapple', 'Tomato 1', 'Cherry 2', 'Apple Red 2', 'Avocado ripe', 'Dates', 'Maracuja', 'Papaya', 'Nut Pecan', 'Pear Stone', 'Cherry Wax Yellow', 'Eggplant', 'Apple Golden 2', 'Guava', 'Beetroot', 'Tomato Maroon', 'Potato Red', 'Apple Red Delicious', 'Cherry Wax Red', 'Kiwi', 'Cherry Wax Black', 'Limes', 'Cantaloupe 2', 'Apple Braeburn', 'Pear', 'Carambula', 'Tomato 3', 'Onion White', 'Cherry 1', 'Strawberry', 'Lychee', 'Redcurrant', 'Rambutan', 'Potato Red Washed', 'Tomato 4', 'Hazelnut', 'Tomato Yellow', 'Plum 3', 'Grape White', 'Pineapple Mini', 'Mulberry', 'Grape Blue', 'Pear Abate', 'Melon Piel de Sapo', 'Pepper Orange', 'Cauliflower', 'Nectarine', 'Salak', 'Cocos', 'Chestnut', 'Blueberry', 'Apple Granny Smith', 'Banana Lady Finger', 'Apricot', 'Walnut', 'Apple Crimson Snow', 'Grapefruit Pink', 'Tangelo', 'Peach Flat', 'Pear Forelle', 'Pepper Red', 'Tomato Cherry Red', 'Pear Williams', 'Clementine', 'Apple Golden 3', 'Apple Red 1', 'Pear 2', 'Plum 2', 'Cantaloupe 1', 'Lemon', 'Physalis with Husk', 'Peach 2', 'Pepino', 'Huckleberry', 'Potato White', 'Pitahaya Red', 'Apple Golden 1', 'Pomelo Sweetie', 'Cherry Rainier', 'Avocado', 'Apple Red Yellow 2', 'Raspberry', 'Mangostan', 'Strawberry Wedge', 'Kaki', 'Mandarine', 'Potato Sweet', 'Cucumber Ripe 2', 'Kumquats', 'Pear Red', 'Ginger Root', 'Physalis', 'Pear Kaiser', 'Peach', 'Corn', 'Grape White 3', 'Apple Red Yellow 1', 'Grape Pink', 'Banana', 'Grape White 4', 'Kohlrabi', 'Pepper Green', 'Watermelon', 'Mango', 'Tomato 2']\n131\n1/1 [==============================] - 0s 91ms/step\nCherry Rainier\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m img \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(testImgPath)\n\u001b[1;32m     38\u001b[0m cv\u001b[38;5;241m.\u001b[39mputText(img, categories[answers[\u001b[38;5;241m0\u001b[39m]],(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m50\u001b[39m), cv\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_COMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m209\u001b[39m, \u001b[38;5;241m19\u001b[39m, \u001b[38;5;241m77\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m cv\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n","\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"],"ename":"error","evalue":"OpenCV(4.7.0) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n","output_type":"error"}]}]}