{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Training model"]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"6a03741b-6dd5-435e-8d8d-ffb6989d96da","_uuid":"8bc14dc0-1c02-4a72-96c2-bf27321b7876","collapsed":false,"execution":{"iopub.execute_input":"2023-07-02T22:37:24.268416Z","iopub.status.busy":"2023-07-02T22:37:24.268025Z","iopub.status.idle":"2023-07-02T23:02:47.068551Z","shell.execute_reply":"2023-07-02T23:02:47.067527Z","shell.execute_reply.started":"2023-07-02T22:37:24.268381Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_3 (Conv2D)           (None, 98, 98, 128)       3584      \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 49, 49, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 47, 47, 64)        73792     \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 45, 45, 32)        18464     \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 22, 22, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 22, 22, 32)        0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 15488)             0         \n","                                                                 \n"," dense_3 (Dense)             (None, 5000)              77445000  \n","                                                                 \n"," dense_4 (Dense)             (None, 1000)              5001000   \n","                                                                 \n"," dense_5 (Dense)             (None, 131)               131131    \n","                                                                 \n","=================================================================\n","Total params: 82,672,971\n","Trainable params: 82,672,971\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Found 67692 images belonging to 131 classes.\n","Found 22688 images belonging to 131 classes.\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-07-02 22:37:28.201089: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"]},{"name":"stdout","output_type":"stream","text":["1058/1058 [==============================] - 276s 260ms/step - loss: 3.5241 - accuracy: 0.1491 - val_loss: 1.9349 - val_accuracy: 0.4614\n","Epoch 2/5\n","1058/1058 [==============================] - 276s 261ms/step - loss: 1.3912 - accuracy: 0.5662 - val_loss: 0.7682 - val_accuracy: 0.7680\n","Epoch 3/5\n","1058/1058 [==============================] - 274s 259ms/step - loss: 0.6346 - accuracy: 0.7964 - val_loss: 0.5061 - val_accuracy: 0.8531\n","Epoch 4/5\n","1058/1058 [==============================] - 277s 262ms/step - loss: 0.4012 - accuracy: 0.8809 - val_loss: 0.3317 - val_accuracy: 0.8969\n","Epoch 5/5\n","1058/1058 [==============================] - 276s 261ms/step - loss: 0.2214 - accuracy: 0.9300 - val_loss: 0.2843 - val_accuracy: 0.9164\n"]}],"source":["import tensorflow as tf\n","import os\n","from keras.utils import img_to_array, load_img\n","import numpy as np\n","import cv2 as cv\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as pltf\n","\n","trainPath = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training'\n","testPath = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test'\n","\n","batchSize = 64      # Reduce value if you have less GPU\n","\n","# # Read in example image and get shape\n","# img = load_img(trainPath + \"/Quince/0_100.jpg\")\n","# plt.imshow(img)\n","# plt.show()\n","\n","# imgA = img_to_array(img)\n","# print(imgA.shape)\n","\n","# Build model\n","model = Sequential()\n","model.add(Conv2D(filters=128, kernel_size=3, activation=\"relu\", input_shape=(100,100,3)))\n","model.add(MaxPooling2D())\n","model.add(Conv2D(filters=64, kernel_size=3, activation=\"relu\"))\n","model.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\n","model.add(MaxPooling2D())\n","model.add(Dropout(0.5))\n","model.add(Flatten())\n","model.add(Dense(5000, activation=\"relu\"))\n","model.add(Dense(1000, activation=\"relu\"))\n","model.add(Dense(131, activation=\"softmax\"))\n","\n","print(model.summary())\n","\n","# Compile model\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n","\n","# Load data\n","train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.3, horizontal_flip=True, vertical_flip=True, zoom_range=0.3)\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(trainPath, target_size=(100,100), batch_size=batchSize, color_mode=\"rgb\", class_mode=\"categorical\", shuffle=True)\n","\n","\n","test_generator = test_datagen.flow_from_directory(testPath, target_size=(100,100), batch_size=batchSize, color_mode=\"rgb\", class_mode=\"categorical\")\n","\n","stepsPerEpoch = np.ceil(train_generator.samples / batchSize)\n","validationSteps = np.ceil(test_generator.samples / batchSize)\n","\n","# Early stopping\n","stop_early = EarlyStopping(monitor=\"val_accuracy\", patience=5)      # Stop fitting model if it doesn't improve by 5\n","\n","history = model.fit(train_generator, steps_per_epoch=stepsPerEpoch, epochs=5, validation_data=test_generator, validation_steps=validationSteps, callbacks=[stop_early])\n","\n","model.save(\"/kaggle/working/fruits360.h5\")     # Add file path to save the model to"]},{"cell_type":"markdown","metadata":{},"source":["# Testing model"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T23:27:00.470742Z","iopub.status.busy":"2023-07-02T23:27:00.470324Z","iopub.status.idle":"2023-07-02T23:27:17.337677Z","shell.execute_reply":"2023-07-02T23:27:17.336443Z","shell.execute_reply.started":"2023-07-02T23:27:00.470705Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: opencv-python-headless 4.7.0.72\n","Uninstalling opencv-python-headless-4.7.0.72:\n","  Successfully uninstalled opencv-python-headless-4.7.0.72\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.8.0.74)\n","Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mModel: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_3 (Conv2D)           (None, 98, 98, 128)       3584      \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 49, 49, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 47, 47, 64)        73792     \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 45, 45, 32)        18464     \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 22, 22, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 22, 22, 32)        0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 15488)             0         \n","                                                                 \n"," dense_3 (Dense)             (None, 5000)              77445000  \n","                                                                 \n"," dense_4 (Dense)             (None, 1000)              5001000   \n","                                                                 \n"," dense_5 (Dense)             (None, 131)               131131    \n","                                                                 \n","=================================================================\n","Total params: 82,672,971\n","Trainable params: 82,672,971\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","['Quince', 'Grapefruit White', 'Granadilla', 'Orange', 'Apple Red 3', 'Grape White 2', 'Corn Husk', 'Tamarillo', 'Banana Red', 'Nectarine Flat', 'Pepper Yellow', 'Nut Forest', 'Pear Monster', 'Fig', 'Tomato Heart', 'Onion Red Peeled', 'Lemon Meyer', 'Onion Red', 'Passion Fruit', 'Cucumber Ripe', 'Cactus fruit', 'Tomato not Ripened', 'Mango Red', 'Apple Pink Lady', 'Pomegranate', 'Plum', 'Pineapple', 'Tomato 1', 'Cherry 2', 'Apple Red 2', 'Avocado ripe', 'Dates', 'Maracuja', 'Papaya', 'Nut Pecan', 'Pear Stone', 'Cherry Wax Yellow', 'Eggplant', 'Apple Golden 2', 'Guava', 'Beetroot', 'Tomato Maroon', 'Potato Red', 'Apple Red Delicious', 'Cherry Wax Red', 'Kiwi', 'Cherry Wax Black', 'Limes', 'Cantaloupe 2', 'Apple Braeburn', 'Pear', 'Carambula', 'Tomato 3', 'Onion White', 'Cherry 1', 'Strawberry', 'Lychee', 'Redcurrant', 'Rambutan', 'Potato Red Washed', 'Tomato 4', 'Hazelnut', 'Tomato Yellow', 'Plum 3', 'Grape White', 'Pineapple Mini', 'Mulberry', 'Grape Blue', 'Pear Abate', 'Melon Piel de Sapo', 'Pepper Orange', 'Cauliflower', 'Nectarine', 'Salak', 'Cocos', 'Chestnut', 'Blueberry', 'Apple Granny Smith', 'Banana Lady Finger', 'Apricot', 'Walnut', 'Apple Crimson Snow', 'Grapefruit Pink', 'Tangelo', 'Peach Flat', 'Pear Forelle', 'Pepper Red', 'Tomato Cherry Red', 'Pear Williams', 'Clementine', 'Apple Golden 3', 'Apple Red 1', 'Pear 2', 'Plum 2', 'Cantaloupe 1', 'Lemon', 'Physalis with Husk', 'Peach 2', 'Pepino', 'Huckleberry', 'Potato White', 'Pitahaya Red', 'Apple Golden 1', 'Pomelo Sweetie', 'Cherry Rainier', 'Avocado', 'Apple Red Yellow 2', 'Raspberry', 'Mangostan', 'Strawberry Wedge', 'Kaki', 'Mandarine', 'Potato Sweet', 'Cucumber Ripe 2', 'Kumquats', 'Pear Red', 'Ginger Root', 'Physalis', 'Pear Kaiser', 'Peach', 'Corn', 'Grape White 3', 'Apple Red Yellow 1', 'Grape Pink', 'Banana', 'Grape White 4', 'Kohlrabi', 'Pepper Green', 'Watermelon', 'Mango', 'Tomato 2']\n","131\n","1/1 [==============================] - 0s 91ms/step\n","Cherry Rainier\n"]},{"ename":"error","evalue":"OpenCV(4.7.0) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m img \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(testImgPath)\n\u001b[1;32m     38\u001b[0m cv\u001b[38;5;241m.\u001b[39mputText(img, categories[answers[\u001b[38;5;241m0\u001b[39m]],(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m50\u001b[39m), cv\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_COMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m209\u001b[39m, \u001b[38;5;241m19\u001b[39m, \u001b[38;5;241m77\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m cv\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n","\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"]}],"source":["!pip uninstall opencv-python-headless -y \n","!pip install opencv-python --upgrade\n","import tensorflow as tf\n","import os\n","from keras.utils import img_to_array, load_img\n","import numpy as np\n","import cv2 as cv\n","\n","# Load model\n","model = tf.keras.models.load_model(\"/kaggle/working/fruits360.h5\")       # Put in model path here\n","print(model.summary())\n","\n","# Load categories\n","source_folder = \"/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test\"\n","categories = os.listdir(source_folder)\n","# categories = categories.sort()\n","print(categories)\n","print(len(categories))      # Should be 131\n","\n","# Load and prepare image\n","def prepareImage(path):\n","    img = load_img(path, target_size=(100,100))\n","    imgArray = img_to_array(img)\n","    # print(imgArray.shape)\n","    imgArray = np.expand_dims(imgArray, axis=0)\n","    imgArray = imgArray / 255.\n","    return imgArray\n","\n","testImgPath = \"/kaggle/input/eggplant/eggplant.jpg\"\n","imageForModel = prepareImage(testImgPath)\n","\n","resultArray = model.predict(imageForModel, verbose=1)\n","answers = np.argmax(resultArray, axis=1)\n","print(categories[answers[0]])\n","\n","# Show image with text below\n","img = cv.imread(testImgPath)\n","cv.putText(img, categories[answers[0]],(0,50), cv.FONT_HERSHEY_COMPLEX, 1, (209, 19, 77), 2)\n","cv.imshow('img', img)\n","cv.waitKey(0)\n","\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
